{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a67c8291",
   "metadata": {},
   "source": [
    "# Redis\n",
    "### Store cars data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4391f29",
   "metadata": {},
   "source": [
    "#### Install needed to run Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8a03c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfb81e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install flask-bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4802709",
   "metadata": {},
   "source": [
    "#### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbb5887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f10dc373",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_carList = pd.read_csv(\"./datasets/Car_listings.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cd33cc",
   "metadata": {},
   "source": [
    "We can see that this dataset has a Price column, which we don't need, beacuse this is a rental company where customers doesn't buy the cars. Because of this we remove the Price column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d11bd19",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Vin</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>35725</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>TX</td>\n",
       "      <td>19VDE2E53EE000083</td>\n",
       "      <td>Acura</td>\n",
       "      <td>ILX6-Speed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Mileage     City State                Vin   Make       Model\n",
       "0  2014    35725  El Paso    TX  19VDE2E53EE000083  Acura  ILX6-Speed"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_carList = df_carList.drop(['Price'], axis = 1)\n",
    "df_carList.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f38daf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_carList = df_carList.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301f275f",
   "metadata": {},
   "source": [
    "#### We need to convert the csv file to JSON, so that we can store the data in redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00ad77ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_carList.to_json('./datasets/cars.json', orient='split', compression='infer', index='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28544ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('./datasets/cars.json', orient ='split', compression = 'infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb70b4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26595bf1",
   "metadata": {},
   "source": [
    "#### Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78e1d09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21835c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = redis.Redis(db=1)\n",
    "#r.flushdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2bf5019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data: [2004, 38235, 'Marietta', ' GA', 'WDBSK75FX4F069367', 'Mercedes-Benz', 'SL-ClassSL500']\n"
     ]
    }
   ],
   "source": [
    "with open('./datasets/cars.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    " \n",
    "    # Print the type of data variable\n",
    "    #print(\"Type:\", type(data))\n",
    "    \n",
    "    #print(\"ITEMS: \", data.items())\n",
    "      \n",
    "    # Print the data of dictionary\n",
    "    #print(\"\\nData:\", data['data'][0]['ID IPEDS Occupation Parent'])\n",
    "    print(\"\\nData:\", data['data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9747219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop og give hver værdi en key som er deres kolonne navn\n",
    "columns = list(df)\n",
    "listOfDict = []\n",
    "\n",
    "def smallDictFunction(co: [], di: {}) -> {}:\n",
    "    smallDicts = {}\n",
    "    for c in co:\n",
    "        for d in di:\n",
    "            if (columns.index(c) == dic.index(d)):\n",
    "                #print(c + ': ' + str(d))\n",
    "                #print(d)\n",
    "                smallDicts[c] = d\n",
    "        \n",
    "    return smallDicts\n",
    "   \n",
    "\n",
    "for dic in data['data']:\n",
    "    listOfDict.append(smallDictFunction(columns, dic))\n",
    "    if (data['data'].index(dic)+1 == 200000):\n",
    "        break    # break here\n",
    "\n",
    "\n",
    "#print(test())\n",
    "#print(smallDicts)\n",
    "print(listOfDict)\n",
    "#print(fullDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51eb64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = [*range(1, (len(listOfDict)+1), 1)]\n",
    "len(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b58982",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped = zip(index_list, listOfDict)\n",
    "fullDict = dict(zipped)\n",
    "print(fullDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c973a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./datasets/carsDict.json\", \"w\") as write_file:\n",
    "    json.dump(fullDict, write_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05b46cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./datasets/carsDict.json') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184422c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dic in data:\n",
    "    p_mydict = pickle.dumps(data[dic])\n",
    "    r.set(dic,p_mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "902ee546",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Year': 2012,\n",
       " 'Mileage': 104716,\n",
       " 'City': 'Tempe',\n",
       " 'State': ' AZ',\n",
       " 'Vin': '1HGCP2F67CA001727',\n",
       " 'Make': 'Honda',\n",
       " 'Model': 'Accord'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_dict = r.get(200000)\n",
    "yourdict = pickle.loads(read_dict)\n",
    "yourdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63283c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile redisSetup.py\n",
    "\n",
    "import redis\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "def redisSimpleConnection():\n",
    "    r = redis.Redis(db=1)\n",
    "    return r\n",
    "    \n",
    "def redisSetup(df):\n",
    "    r = redis.Redis(db=1)\n",
    "    #r.flushdb()\n",
    "\n",
    "    with open('./datasets/cars.json') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    # Loop og give hver værdi en key som er deres kolonne navn\n",
    "    columns = list(df)\n",
    "    listOfDict = []\n",
    "\n",
    "    def smallDictFunction(co: [], di: {}) -> {}:\n",
    "        smallDicts = {}\n",
    "        for c in co:\n",
    "            for d in di:\n",
    "                if (columns.index(c) == dic.index(d)):\n",
    "                    smallDicts[c] = d\n",
    "\n",
    "        return smallDicts\n",
    "\n",
    "\n",
    "    for dic in data['data']:\n",
    "        listOfDict.append(smallDictFunction(columns, dic))\n",
    "        if (data['data'].index(dic)+1 == 200000):\n",
    "            break    # break here\n",
    "\n",
    "    index_list = [*range(1, (len(listOfDict)+1), 1)]\n",
    "    len(index_list)\n",
    "\n",
    "\n",
    "    zipped = zip(index_list, listOfDict)\n",
    "    fullDict = dict(zipped)\n",
    "\n",
    "    with open(\"./datasets/carsDict.json\", \"w\") as write_file:\n",
    "        json.dump(fullDict, write_file, indent=4)\n",
    "\n",
    "    with open('./datasets/carsDict.json') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    for dic in data:\n",
    "        p_mydict = pickle.dumps(data[dic])\n",
    "        r.set(dic,p_mydict)\n",
    "\n",
    "    read_dict = r.get(200000)\n",
    "    yourdict = pickle.loads(read_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ca5221",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python redisSetup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e29af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from redisFile import redisConnection\n",
    "#redisConnection(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01307727",
   "metadata": {},
   "source": [
    "#### Postgres\n",
    "Vi skal kunne søge i postgres efter en person, lave den person inclussiv addresse om til dict og smide den i mongo i samme dict som redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bea23b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f657462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea36b64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def config(filename='../Postgresql/postgresDB.ini', section='postgresql'):\n",
    "    # create a parser\n",
    "    parser = ConfigParser()\n",
    "    # read config file\n",
    "    parser.read(filename)\n",
    "\n",
    "    # get section, default to postgresql\n",
    "    db = {}\n",
    "    if parser.has_section(section):\n",
    "        params = parser.items(section)\n",
    "        for param in params:\n",
    "            db[param[0]] = param[1]\n",
    "    else:\n",
    "        raise Exception('Section {0} not found in the {1} file'.format(section, filename))\n",
    "\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3296fa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def createDict(infoTuple, columnList, index):\n",
    "    infoList = []\n",
    "    for i in infoTuple:\n",
    "        infoList.append(i)\n",
    "        if (infoTuple.index(i) == index):\n",
    "            break;\n",
    "    return(dict(zip(columnList, infoList)))\n",
    "\n",
    "fullUserDict= {}\n",
    "def connect():\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # read connection parameters\n",
    "        params = config()\n",
    "\n",
    "        # connect to the PostgreSQL server\n",
    "        print('Connecting to the PostgreSQL database...')\n",
    "        conn = psycopg2.connect(**params)\n",
    "\t\t\n",
    "        # create a cursor\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "\t# execute a statement\n",
    "        print('Retrieving data:')\n",
    "        print('--------------')\n",
    "        #Retrieving data\n",
    "        cur.execute('SELECT * from users where user_id = '+str(208))\n",
    "        user = cur.fetchone()\n",
    "        cur.execute('SELECT role from roles where role_id = '+str(user[6]))\n",
    "        role = cur.fetchone()\n",
    "        # Saving the user as a dict\n",
    "        userTableColumns = ['user_id', 'firstName', 'lastName', 'age', 'email']\n",
    "        userDict = createDict(user, userTableColumns, 4)\n",
    "        userDict[\"role\"] = role[0]\n",
    "        print(userDict)\n",
    "        print('--------------')\n",
    "        \n",
    "        cur.execute('SELECT address_id from users where user_id = '+str(208))\n",
    "        address_id = cur.fetchone()\n",
    "        cur.execute('SELECT * from address where address_id = '+str(address_id[0]))\n",
    "        address = cur.fetchone()\n",
    "        zipcode = address[2]\n",
    "        cur.execute('SELECT * from cities where zipcode = '+str(zipcode))\n",
    "        city = cur.fetchone()\n",
    "        addressList = list(address)\n",
    "        addressList.append(city[1])\n",
    "        \n",
    "        addressTableColumns = ['address_id', 'address', 'zipcode', 'city']\n",
    "        addressDict = createDict(addressList, addressTableColumns, 3)\n",
    "        print(addressDict)\n",
    "        print('--------------')\n",
    "        \n",
    "        fullUserDict = userDict\n",
    "        fullUserDict['address'] = addressDict\n",
    "        \n",
    "       \n",
    "\t# close the communication with the PostgreSQL\n",
    "        cur.close()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()\n",
    "            print('Database connection closed.')\n",
    "            #print(fullUserDict)\n",
    "            return fullUserDict\n",
    "            \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    connect()\n",
    "    \n",
    "fullUserDict = connect()\n",
    "print(fullUserDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "17552029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting postgresSetup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile postgresSetup.py\n",
    "\n",
    "\n",
    "from configparser import ConfigParser\n",
    "import psycopg2\n",
    "\n",
    "def config(filename='../Postgresql/postgresDB.ini', section='postgresql'):\n",
    "    # create a parser\n",
    "    parser = ConfigParser()\n",
    "    # read config file\n",
    "    parser.read(filename)\n",
    "\n",
    "    # get section, default to postgresql\n",
    "    db = {}\n",
    "    if parser.has_section(section):\n",
    "        params = parser.items(section)\n",
    "        for param in params:\n",
    "            db[param[0]] = param[1]\n",
    "    else:\n",
    "        raise Exception('Section {0} not found in the {1} file'.format(section, filename))\n",
    "\n",
    "    return db\n",
    "\n",
    "\n",
    "def createDict(infoTuple, columnList, index):\n",
    "    infoList = []\n",
    "    for i in infoTuple:\n",
    "        infoList.append(i)\n",
    "        if (infoTuple.index(i) == index):\n",
    "            break;\n",
    "    return(dict(zip(columnList, infoList)))\n",
    "\n",
    "fullUserDict= {}\n",
    "\n",
    "def retrieveUserInfo(uId, cur):\n",
    "    #Retrieving data\n",
    "    cur.execute('SELECT * from users where user_id = '+str(uId))\n",
    "    user = cur.fetchone()\n",
    "    cur.execute('SELECT role from roles where role_id = '+str(user[6]))\n",
    "    role = cur.fetchone()\n",
    "    # Saving the user as a dict\n",
    "    userTableColumns = ['user_id', 'firstName', 'lastName', 'age', 'email']\n",
    "    userDict = createDict(user, userTableColumns, 4)\n",
    "    userDict[\"role\"] = role[0]\n",
    "    \n",
    "    return userDict\n",
    "\n",
    "def retrieveAddressInfo(uId, cur):\n",
    "    cur.execute('SELECT address_id from users where user_id = '+str(uId))\n",
    "    address_id = cur.fetchone()\n",
    "    cur.execute('SELECT * from address where address_id = '+str(address_id[0]))\n",
    "    address = cur.fetchone()\n",
    "    zipcode = address[2]\n",
    "    cur.execute('SELECT * from cities where zipcode = '+str(zipcode))\n",
    "    city = cur.fetchone()\n",
    "    addressList = list(address)\n",
    "    addressList.append(city[1])\n",
    "    \n",
    "    addressTableColumns = ['address_id', 'address', 'zipcode', 'city']\n",
    "    addressDict = createDict(addressList, addressTableColumns, 3)\n",
    "\n",
    "    return addressDict\n",
    "\n",
    "def connect(uId):\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # read connection parameters\n",
    "        params = config()\n",
    "\n",
    "        # connect to the PostgreSQL server\n",
    "        print('Connecting to the PostgreSQL database...')\n",
    "        conn = psycopg2.connect(**params)\n",
    "\t\t\n",
    "        # create a cursor\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "\t# execute a statement\n",
    "        addressDict = retrieveAddressInfo(uId, cur)\n",
    "\n",
    "        fullUserDict = retrieveUserInfo(uId, cur)\n",
    "        fullUserDict['address'] = addressDict\n",
    "        \n",
    "       \n",
    "\t# close the communication with the PostgreSQL\n",
    "        cur.close()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()\n",
    "            print('Database connection closed.')\n",
    "            #print(fullUserDict)\n",
    "            return fullUserDict\n",
    "            \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    connect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff40e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from postgresSetup import connect\n",
    "#connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093f98d0",
   "metadata": {},
   "source": [
    "#### MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e034d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880270ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import bson\n",
    "import pickle\n",
    "import base64\n",
    "\n",
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "\n",
    "#use database named \"organisation\"\n",
    "mydb = myclient[\"ExamProject\"]\n",
    "\n",
    "#use collection named \"developers\"\n",
    "mycol = mydb[\"Temporary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fde10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(n):\n",
    "    dataList = []\n",
    "    tic = time.perf_counter()\n",
    "    d = r.get(n)\n",
    "    yourdict = pickle.loads(d)\n",
    "    dataList.append(yourdict)\n",
    "    toc = time.perf_counter()\n",
    "    dataList.append(toc - tic)\n",
    "    return dataList\n",
    "\n",
    "car = getData(1)\n",
    "car[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f083868d",
   "metadata": {},
   "outputs": [],
   "source": [
    "booking = {}\n",
    "booking['user'] = fullUserDict\n",
    "booking['car'] = car[0]\n",
    "\n",
    "print(booking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76936f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mycol.insert_one(booking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e5139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in mycol.find():\n",
    "    print(x)\n",
    "    print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "36923b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mongoDBSetup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mongoDBSetup.py\n",
    "\n",
    "\n",
    "import pymongo\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "\n",
    "def mongoConnection(connection_string, database_name, collection_name):\n",
    "    myclient = pymongo.MongoClient(connection_string)\n",
    "\n",
    "    #use database named \"organisation\"\n",
    "    mydb = myclient[database_name]\n",
    "\n",
    "    #use collection named \"developers\"\n",
    "    mycol = mydb[collection_name]\n",
    "\n",
    "    return mycol\n",
    "\n",
    "def getDataFromMongo(r, n):\n",
    "    dataList = []\n",
    "    tic = time.perf_counter()\n",
    "    d = r.get(n)\n",
    "    yourdict = pickle.loads(d)\n",
    "    dataList.append(yourdict)\n",
    "    toc = time.perf_counter()\n",
    "    dataList.append(toc - tic)\n",
    "    return dataList\n",
    "\n",
    "def createBooking(mycol, user, car):\n",
    "    booking = {}\n",
    "    booking['user'] = user\n",
    "    booking['car'] = car\n",
    "    \n",
    "    mycol.insert_one(booking)\n",
    "\n",
    "def findBookings(mycol):\n",
    "    bookingList = []\n",
    "    for x in mycol.find():\n",
    "        bookingList.append(x)\n",
    "    print(bookingList)\n",
    "    return bookingList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94da2be1",
   "metadata": {},
   "source": [
    "#### Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47191da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485a5882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "from neo4j.exceptions import ServiceUnavailable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0d368a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class App:\n",
    "\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password), database='analisys')\n",
    "\n",
    "    def close(self):\n",
    "        # Don't forget to close the driver connection when you are finished with it\n",
    "        self.driver.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def enable_log(level, output_stream):\n",
    "        handler = logging.StreamHandler(output_stream)\n",
    "        handler.setLevel(level)\n",
    "        logging.getLogger(\"neo4j\").addHandler(handler)\n",
    "        logging.getLogger(\"neo4j\").setLevel(level)\n",
    "\n",
    "    def create_friendship(self, user_id, \n",
    "                      firstName, \n",
    "                      lastName,\n",
    "                      age,\n",
    "                      email,\n",
    "                      address,\n",
    "                      zipcode,\n",
    "                      city,\n",
    "                      year,\n",
    "                      mileage,\n",
    "                      cityC,\n",
    "                      state,\n",
    "                      vin,\n",
    "                      make,\n",
    "                      model, books):\n",
    "        with self.driver.session() as session:\n",
    "            # Write transactions allow the driver to handle retries and transient errors\n",
    "            result = session.write_transaction(\n",
    "                self._create_and_return_friendship, user_id, \n",
    "                      firstName, \n",
    "                      lastName,\n",
    "                      age,\n",
    "                      email,\n",
    "                      address,\n",
    "                      zipcode,\n",
    "                      city,\n",
    "                      year,\n",
    "                      mileage,\n",
    "                      cityC,\n",
    "                      state,\n",
    "                      vin,\n",
    "                      make,\n",
    "                      model, books)\n",
    "            for row in result:\n",
    "                print(\"Created friendship between: {u}, {c} from {books}\"\n",
    "                      .format(\n",
    "                          u=row['u'],\n",
    "                          c=row['c'],\n",
    "                          books=row['books']))\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_and_return_friendship(tx, user_id, \n",
    "                      firstName, \n",
    "                      lastName,\n",
    "                      age,\n",
    "                      email,\n",
    "                      address,\n",
    "                      zipcode,\n",
    "                      city,\n",
    "                      year,\n",
    "                      mileage,\n",
    "                      cityC,\n",
    "                      state,\n",
    "                      vin,\n",
    "                      make,\n",
    "                      model, books):\n",
    "        # To learn more about the Cypher syntax, see https://neo4j.com/docs/cypher-manual/current/\n",
    "        # The Reference Card is also a good resource for keywords https://neo4j.com/docs/cypher-refcard/current/\n",
    "        query = (\n",
    "            \"MERGE (u:User { user_id: $user_id, firstName: $firstName, lastName: $lastName, age: $age, email: $email, address: $address, zipcode: $zipcode, city: $city}) \"\n",
    "            \"MERGE (c:Car { year: $year, mileage: $mileage, cityC: $cityC, state: $state, vin: $vin, make: $make, model: $model }) \"\n",
    "            \"MERGE (u)-[k:BOOKS { from: $books }]->(c) \"\n",
    "            \"RETURN u, c, k\"\n",
    "        )\n",
    "        result = tx.run(query, user_id=user_id, firstName=firstName, lastName=lastName, age=age, email=email, \n",
    "                        address=address, zipcode=zipcode, city=city, year=year, mileage=mileage, cityC=cityC, state=state,\n",
    "                        vin=vin, make=make, model=model, books=books)\n",
    "        try:\n",
    "            return [{\n",
    "                        \"u\": row[\"u\"][\"user_id\"],\n",
    "                        \"c\": row[\"c\"][\"year\"],\n",
    "                        \"books\": row[\"k\"][\"books\"]\n",
    "                    }\n",
    "                    for row in result]\n",
    "        # Capture any errors along with the query and data for traceability\n",
    "        except ServiceUnavailable as exception:\n",
    "            logging.error(\"{query} raised an error: \\n {exception}\".format(\n",
    "                query=query, exception=exception))\n",
    "            raise\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    bolt_url = \"bolt://localhost:7687\"\n",
    "    user = \"neo4j\"\n",
    "    password = \"1234\"\n",
    "    App.enable_log(logging.INFO, sys.stdout)\n",
    "    app = App(bolt_url, user, password)\n",
    "    \n",
    "    infoList = []\n",
    "    for x in mycol.find():\n",
    "        #print(list(x.values())[1])\n",
    "        for key, values in x.items():\n",
    "            if (key == 'user'):\n",
    "                #x = thisdict[\"model\"]\n",
    "                listVU = list(values)\n",
    "                #print(values)\n",
    "\n",
    "                for k, v in values.items():\n",
    "                    infoList.append(v)\n",
    "                infoList.pop()\n",
    "                infoList.pop()\n",
    "                for k, v in values['address'].items():\n",
    "                    infoList.append(v)\n",
    "                del infoList[5]\n",
    "                #print(listVU)\n",
    "                print('--------------')\n",
    "            if (key == 'car'):\n",
    "                print(values)\n",
    "                for k, v in values.items():\n",
    "                    infoList.append(v)\n",
    "            #print('key: ' + key)\n",
    "            #print('values: ' + str(values))\n",
    "        print(infoList)\n",
    "        app.create_friendship(infoList[0], infoList[1], infoList[2], infoList[3], infoList[4], infoList[5], \n",
    "                              infoList[6], infoList[7], infoList[8], infoList[9], infoList[10], infoList[11], \n",
    "                              infoList[12], infoList[13], infoList[14], 'books')\n",
    "        print('------------------')\n",
    "        infoList = []\n",
    "    \n",
    "    #app.create_friendship(405, 'Belinda', 'Foster', 44, 'b.foster@randatmail.com', 'Kongshøj Allé 65', 4220, 'Korsør',\n",
    "                         #2017, 15630, 'Katy', 'TX', '1FMJU1JT4HEA55066', 'Ford', 'ExpeditionXLT', 'books')\n",
    "    #app.find_person(\"Alice\")\n",
    "    \n",
    "    app.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec3b8bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting neo4jSetup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile neo4jSetup.py\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "from neo4j.exceptions import ServiceUnavailable\n",
    "\n",
    "\n",
    "def close(driver):\n",
    "    driver.close()\n",
    "\n",
    "def connectNeo(uri, user, password, db):\n",
    "    driver = GraphDatabase.driver(uri, auth=(user, password), database=db)\n",
    "    return driver\n",
    "\n",
    "def create_relationsship_books(tx, user_id, \n",
    "                      firstName, \n",
    "                      lastName,\n",
    "                      age,\n",
    "                      email,\n",
    "                      address,\n",
    "                      zipcode,\n",
    "                      city,\n",
    "                      year,\n",
    "                      mileage,\n",
    "                      cityC,\n",
    "                      state,\n",
    "                      vin,\n",
    "                      make,\n",
    "                      model, books):\n",
    "    query = (\n",
    "            \"MERGE (u:User { user_id: $user_id, firstName: $firstName, lastName: $lastName, age: $age, email: $email, address: $address, zipcode: $zipcode, city: $city}) \"\n",
    "            \"MERGE (c:Car { year: $year, mileage: $mileage, cityC: $cityC, state: $state, vin: $vin, make: $make, model: $model }) \"\n",
    "            \"MERGE (u)-[k:BOOKS { from: $books }]->(c) \"\n",
    "            \"RETURN u, c, k\"\n",
    "        )\n",
    "    result = tx.run(query, user_id=user_id, firstName=firstName, lastName=lastName, age=age, email=email, \n",
    "                    address=address, zipcode=zipcode, city=city, year=year, mileage=mileage, cityC=cityC, state=state,\n",
    "                    vin=vin, make=make, model=model, books=books)\n",
    "    try:\n",
    "        return [{\n",
    "                    \"u\": row[\"u\"][\"user_id\"],\n",
    "                    \"c\": row[\"c\"][\"year\"],\n",
    "                    \"books\": row[\"k\"][\"books\"]\n",
    "                }\n",
    "                for row in result]\n",
    "    # Capture any errors along with the query and data for traceability\n",
    "    except ServiceUnavailable as exception:\n",
    "        logging.error(\"{query} raised an error: \\n {exception}\".format(\n",
    "            query=query, exception=exception))\n",
    "        raise\n",
    "\n",
    "def createNodes(driver, user_id, \n",
    "                      firstName, \n",
    "                      lastName,\n",
    "                      age,\n",
    "                      email,\n",
    "                      address,\n",
    "                      zipcode,\n",
    "                      city,\n",
    "                      year,\n",
    "                      mileage,\n",
    "                      cityC,\n",
    "                      state,\n",
    "                      vin,\n",
    "                      make,\n",
    "                      model, books):\n",
    "    with driver.session() as session:\n",
    "        session.write_transaction(create_relationsship_books, user_id, \n",
    "                      firstName, \n",
    "                      lastName,\n",
    "                      age,\n",
    "                      email,\n",
    "                      address,\n",
    "                      zipcode,\n",
    "                      city,\n",
    "                      year,\n",
    "                      mileage,\n",
    "                      cityC,\n",
    "                      state,\n",
    "                      vin,\n",
    "                      make,\n",
    "                      model, books)\n",
    "\n",
    "def createAnalysis(mycol, driver):\n",
    "    infoList = []\n",
    "    for x in mycol.find():\n",
    "        for key, values in x.items():\n",
    "            if (key == 'user'):\n",
    "                for k, v in values.items():\n",
    "                    infoList.append(v)\n",
    "                infoList.pop()\n",
    "                infoList.pop()\n",
    "                for k, v in values['address'].items():\n",
    "                    infoList.append(v)\n",
    "                del infoList[5]\n",
    "            if (key == 'car'):\n",
    "                for k, v in values.items():\n",
    "                    infoList.append(v)\n",
    "\n",
    "        createNodes(driver, infoList[0], infoList[1], infoList[2], infoList[3], infoList[4], infoList[5], \n",
    "                                infoList[6], infoList[7], infoList[8], infoList[9], infoList[10], infoList[11], \n",
    "                                infoList[12], infoList[13], infoList[14], 'books')\n",
    "\n",
    "        infoList = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "325a8f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting functions.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile functions.py\n",
    "\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "from redisSetup import *\n",
    "from postgresSetup import *\n",
    "from mongoDBSetup import *\n",
    "from neo4jSetup import *\n",
    "\n",
    "# ---------- Redis -------------\n",
    "r = redisSimpleConnection()\n",
    "def getCar(n):\n",
    "    read_dict = r.get(n)\n",
    "    car = pickle.loads(read_dict)\n",
    "    return car\n",
    "\n",
    "# ---------- Postgres -------------\n",
    "def getUser(n):\n",
    "    user = connect(n)\n",
    "    return user\n",
    "\n",
    "# ---------- Mongo -------------\n",
    "def createBookingLast(connection_string, database_name, collection_name, uId, cId):\n",
    "    mycol = mongoConnection(connection_string, database_name, collection_name)\n",
    "    user = getUser(uId)\n",
    "    car = getCar(cId)\n",
    "    createBooking(mycol, user, car)\n",
    "\n",
    "def findBookingsLast(connection_string, database_name, collection_name):\n",
    "    mycol = mongoConnection(connection_string, database_name, collection_name)\n",
    "    return findBookings(mycol)\n",
    "\n",
    "# ---------- Neo4j -------------\n",
    "def createAnalysisLast(connection_string, database_name, collection_name):\n",
    "    mycol = mongoConnection(connection_string, database_name, collection_name)\n",
    "    bolt_url = \"bolt://localhost:7687\"\n",
    "    user = \"neo4j\"\n",
    "    password = \"1234\"\n",
    "    db = 'analysis'\n",
    "    \n",
    "    driver = connectNeo(bolt_url, user, password, db)\n",
    "    createAnalysis(mycol, driver)\n",
    "    close(driver)\n",
    "    return 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e746b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "013e321d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting application.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile application.py\n",
    "\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "from functions import *\n",
    "from threading import Timer\n",
    "\n",
    "app = Flask(__name__, template_folder='hmtl_documents')\n",
    "\n",
    "connection_string = \"mongodb://localhost:27017/\"\n",
    "database_name = \"ExamProject\"\n",
    "collection_name = \"Bookings\"\n",
    "\n",
    "@app.route('/')\n",
    "def bookingEndpoint():\n",
    "    return render_template('booking.html')\n",
    "\n",
    "@app.route('/booked', methods=['GET', 'POST'])\n",
    "def booked():\n",
    "    if request.method == 'POST':\n",
    "        uId = request.form['uId']\n",
    "        cId = request.form['cId']\n",
    "        \n",
    "        createBookingLast(connection_string, database_name, collection_name, uId, cId)\n",
    "          \n",
    "        return render_template(\"booked.html\", data=[uId, cId])\n",
    "\n",
    "@app.route('/admin')\n",
    "def admin():\n",
    "    bookings = findBookingsLast(connection_string, database_name, collection_name)\n",
    "    \n",
    "    return render_template('admin.html', bookings=bookings)\n",
    "\n",
    "@app.route('/adminAnalysis', methods=['GET', 'POST'])\n",
    "def adminAnalysis():\n",
    "    if request.method == 'POST':\n",
    "        createAnalysisLast(connection_string, database_name, collection_name)\n",
    "        \n",
    "        return render_template(\"adminAnalysis.html\")\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8065a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python application.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5f914d",
   "metadata": {},
   "source": [
    "http://localhost:5000/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
