{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a67c8291",
   "metadata": {},
   "source": [
    "# Redis\n",
    "### Store cars data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4391f29",
   "metadata": {},
   "source": [
    "#### Install needed to run Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8a03c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfb81e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install flask-bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4802709",
   "metadata": {},
   "source": [
    "#### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dbb5887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f10dc373",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_carList = pd.read_csv(\"./datasets/Car_listings.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cd33cc",
   "metadata": {},
   "source": [
    "We can see that this dataset has a Price column, which we don't need, beacuse this is a rental company where customers doesn't buy the cars. Because of this we remove the Price column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4d11bd19",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Price'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17712/1157964129.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_carList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_carList\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Price'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_carList\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_carList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4904\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4905\u001b[0m         \"\"\"\n\u001b[1;32m-> 4906\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4907\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4908\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4148\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4149\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4150\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4152\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   4183\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4184\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4185\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4186\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6015\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6017\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6019\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Price'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df_carList = df_carList.drop(['Price'], axis = 1)\n",
    "df_carList.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1c808a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_carList = df_carList.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301f275f",
   "metadata": {},
   "source": [
    "#### We need to convert the csv file to JSON, so that we can store the data in redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "00ad77ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_carList.to_json('./datasets/cars.json', orient='split', compression='infer', index='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "28544ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('./datasets/cars.json', orient ='split', compression = 'infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3bb70b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Vin</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400278</th>\n",
       "      <td>2016</td>\n",
       "      <td>24925</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>AZ</td>\n",
       "      <td>1HGCR2F82GA002625</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Accord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330804</th>\n",
       "      <td>2017</td>\n",
       "      <td>15630</td>\n",
       "      <td>Katy</td>\n",
       "      <td>TX</td>\n",
       "      <td>1FMJU1JT4HEA55066</td>\n",
       "      <td>Ford</td>\n",
       "      <td>ExpeditionXLT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836297</th>\n",
       "      <td>2015</td>\n",
       "      <td>29835</td>\n",
       "      <td>Wilminton</td>\n",
       "      <td>OH</td>\n",
       "      <td>3VWLA7AJ0FM239576</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Jetta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778225</th>\n",
       "      <td>2013</td>\n",
       "      <td>53100</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>TX</td>\n",
       "      <td>4T1BK1EB5DU009824</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>AvalonXLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539953</th>\n",
       "      <td>2017</td>\n",
       "      <td>6636</td>\n",
       "      <td>Ballwin</td>\n",
       "      <td>MO</td>\n",
       "      <td>3KPFK4A72HE061487</td>\n",
       "      <td>Kia</td>\n",
       "      <td>ForteLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508098</th>\n",
       "      <td>2012</td>\n",
       "      <td>42510</td>\n",
       "      <td>Wappingers Falls</td>\n",
       "      <td>NY</td>\n",
       "      <td>1C4BJWCG4CL117326</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>Wrangler4WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511276</th>\n",
       "      <td>2012</td>\n",
       "      <td>87207</td>\n",
       "      <td>Watertown</td>\n",
       "      <td>WI</td>\n",
       "      <td>1C4BJWDG8CL102827</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>Wrangler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793116</th>\n",
       "      <td>2012</td>\n",
       "      <td>90234</td>\n",
       "      <td>Knoxville</td>\n",
       "      <td>TN</td>\n",
       "      <td>5TDBK3EH5CS153140</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Highlander4WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428259</th>\n",
       "      <td>2016</td>\n",
       "      <td>19</td>\n",
       "      <td>Grapevine</td>\n",
       "      <td>TX</td>\n",
       "      <td>5FNRL5H43GB168472</td>\n",
       "      <td>Honda</td>\n",
       "      <td>OdysseyEX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339600</th>\n",
       "      <td>2012</td>\n",
       "      <td>206496</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>NC</td>\n",
       "      <td>1FT7W2BT8CEC38427</td>\n",
       "      <td>Ford</td>\n",
       "      <td>Super</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>852122 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Year  Mileage              City State                Vin        Make  \\\n",
       "400278  2016    24925            Tucson    AZ  1HGCR2F82GA002625       Honda   \n",
       "330804  2017    15630              Katy    TX  1FMJU1JT4HEA55066        Ford   \n",
       "836297  2015    29835         Wilminton    OH  3VWLA7AJ0FM239576  Volkswagen   \n",
       "778225  2013    53100       San Antonio    TX  4T1BK1EB5DU009824      Toyota   \n",
       "539953  2017     6636           Ballwin    MO  3KPFK4A72HE061487         Kia   \n",
       "...      ...      ...               ...   ...                ...         ...   \n",
       "508098  2012    42510  Wappingers Falls    NY  1C4BJWCG4CL117326        Jeep   \n",
       "511276  2012    87207         Watertown    WI  1C4BJWDG8CL102827        Jeep   \n",
       "793116  2012    90234         Knoxville    TN  5TDBK3EH5CS153140      Toyota   \n",
       "428259  2016       19         Grapevine    TX  5FNRL5H43GB168472       Honda   \n",
       "339600  2012   206496           Raleigh    NC  1FT7W2BT8CEC38427        Ford   \n",
       "\n",
       "                Model  \n",
       "400278         Accord  \n",
       "330804  ExpeditionXLT  \n",
       "836297          Jetta  \n",
       "778225      AvalonXLE  \n",
       "539953        ForteLX  \n",
       "...               ...  \n",
       "508098    Wrangler4WD  \n",
       "511276       Wrangler  \n",
       "793116  Highlander4WD  \n",
       "428259      OdysseyEX  \n",
       "339600          Super  \n",
       "\n",
       "[852122 rows x 7 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ad9a4b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "db8fc35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = redis.Redis(db=1)\n",
    "#r.flushdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f2bf5019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data: [2016, 24925, 'Tucson', ' AZ', '1HGCR2F82GA002625', 'Honda', 'Accord']\n"
     ]
    }
   ],
   "source": [
    "with open('./datasets/cars.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    " \n",
    "    # Print the type of data variable\n",
    "    #print(\"Type:\", type(data))\n",
    "    \n",
    "    #print(\"ITEMS: \", data.items())\n",
    "      \n",
    "    # Print the data of dictionary\n",
    "    #print(\"\\nData:\", data['data'][0]['ID IPEDS Occupation Parent'])\n",
    "    print(\"\\nData:\", data['data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f9747219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop og give hver værdi en key som er deres kolonne navn\n",
    "columns = list(df)\n",
    "listOfDict = []\n",
    "\n",
    "def smallDictFunction(co: [], di: {}) -> {}:\n",
    "    smallDicts = {}\n",
    "    for c in co:\n",
    "        for d in di:\n",
    "            if (columns.index(c) == dic.index(d)):\n",
    "                #print(c + ': ' + str(d))\n",
    "                #print(d)\n",
    "                smallDicts[c] = d\n",
    "        \n",
    "    return smallDicts\n",
    "   \n",
    "\n",
    "for dic in data['data']:\n",
    "    listOfDict.append(smallDictFunction(columns, dic))\n",
    "    if (data['data'].index(dic)+1 == 200000):\n",
    "        break    # break here\n",
    "\n",
    "\n",
    "#print(test())\n",
    "#print(smallDicts)\n",
    "print(listOfDict)\n",
    "#print(fullDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e51eb64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_list = [*range(1, (len(listOfDict)+1), 1)]\n",
    "len(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "27b58982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zipped = zip(index_list, listOfDict)\n",
    "fullDict = dict(zipped)\n",
    "print(fullDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "34c973a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./datasets/carsDict.json\", \"w\") as write_file:\n",
    "    json.dump(fullDict, write_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c05b46cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./datasets/carsDict.json') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b18e159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dic in data:\n",
    "    p_mydict = pickle.dumps(data[dic])\n",
    "    r.set(dic,p_mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "236dcd07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Year': 2012,\n",
       " 'Mileage': 104716,\n",
       " 'City': 'Tempe',\n",
       " 'State': ' AZ',\n",
       " 'Vin': '1HGCP2F67CA001727',\n",
       " 'Make': 'Honda',\n",
       " 'Model': 'Accord'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_dict = r.get(200000)\n",
    "yourdict = pickle.loads(read_dict)\n",
    "yourdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0eb231",
   "metadata": {},
   "source": [
    "#### Postgres\n",
    "Vi skal kunne søge i postgres efter en person, lave den person inclussiv addresse om til dict og smide den i mongo i samme dict som redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8b4069e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2\n",
      "  Downloading psycopg2-2.9.3-cp39-cp39-win_amd64.whl (1.2 MB)\n",
      "Installing collected packages: psycopg2\n",
      "Successfully installed psycopg2-2.9.3\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9fc803a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fd6c57fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    database=\"postgres\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "900c6089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def config(filename='../Postgresql/postgresDB.ini', section='postgresql'):\n",
    "    # create a parser\n",
    "    parser = ConfigParser()\n",
    "    # read config file\n",
    "    parser.read(filename)\n",
    "\n",
    "    # get section, default to postgresql\n",
    "    db = {}\n",
    "    if parser.has_section(section):\n",
    "        params = parser.items(section)\n",
    "        for param in params:\n",
    "            db[param[0]] = param[1]\n",
    "    else:\n",
    "        raise Exception('Section {0} not found in the {1} file'.format(section, filename))\n",
    "\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "3e417b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Retrieving data:\n",
      "--------------\n",
      "{'user_id': 405, 'firstName': 'Belinda', 'lastName': 'Foster', 'age': 44, 'email': 'b.foster@randatmail.com', 'role': 'user'}\n",
      "--------------\n",
      "{'address_id': 9, 'address': 'Kongshøj Allé 65', 'zipcode': 4220, 'city': 'Korsør'}\n",
      "--------------\n",
      "Database connection closed.\n",
      "Connecting to the PostgreSQL database...\n",
      "Retrieving data:\n",
      "--------------\n",
      "{'user_id': 405, 'firstName': 'Belinda', 'lastName': 'Foster', 'age': 44, 'email': 'b.foster@randatmail.com', 'role': 'user'}\n",
      "--------------\n",
      "{'address_id': 9, 'address': 'Kongshøj Allé 65', 'zipcode': 4220, 'city': 'Korsør'}\n",
      "--------------\n",
      "Database connection closed.\n",
      "{'user_id': 405, 'firstName': 'Belinda', 'lastName': 'Foster', 'age': 44, 'email': 'b.foster@randatmail.com', 'role': 'user', 'address': {'address_id': 9, 'address': 'Kongshøj Allé 65', 'zipcode': 4220, 'city': 'Korsør'}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def createDict(infoTuple, columnList, index):\n",
    "    infoList = []\n",
    "    for i in infoTuple:\n",
    "        infoList.append(i)\n",
    "        if (infoTuple.index(i) == index):\n",
    "            break;\n",
    "    return(dict(zip(columnList, infoList)))\n",
    "\n",
    "fullUserDict= {}\n",
    "def connect():\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # read connection parameters\n",
    "        params = config()\n",
    "\n",
    "        # connect to the PostgreSQL server\n",
    "        print('Connecting to the PostgreSQL database...')\n",
    "        conn = psycopg2.connect(**params)\n",
    "\t\t\n",
    "        # create a cursor\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "\t# execute a statement\n",
    "        print('Retrieving data:')\n",
    "        print('--------------')\n",
    "        #Retrieving data\n",
    "        cur.execute('SELECT * from users where user_id = '+str(405))\n",
    "        user = cur.fetchone()\n",
    "        cur.execute('SELECT role from roles where role_id = '+str(user[6]))\n",
    "        role = cur.fetchone()\n",
    "        # Saving the user as a dict\n",
    "        userTableColumns = ['user_id', 'firstName', 'lastName', 'age', 'email', 'role']\n",
    "        userDict = createDict(user, userTableColumns, 4)\n",
    "        userDict[\"role\"] = role[0]\n",
    "        print(userDict)\n",
    "        print('--------------')\n",
    "        \n",
    "        cur.execute('SELECT address_id from users where user_id = '+str(405))\n",
    "        address_id = cur.fetchone()\n",
    "        cur.execute('SELECT * from address where address_id = '+str(address_id[0]))\n",
    "        address = cur.fetchone()\n",
    "        zipcode = address[2]\n",
    "        cur.execute('SELECT * from cities where zipcode = '+str(zipcode))\n",
    "        city = cur.fetchone()\n",
    "        addressList = list(address)\n",
    "        addressList.append(city[1])\n",
    "        \n",
    "        addressTableColumns = ['address_id', 'address', 'zipcode', 'city']\n",
    "        addressDict = createDict(addressList, addressTableColumns, 3)\n",
    "        print(addressDict)\n",
    "        print('--------------')\n",
    "        \n",
    "        fullUserDict = userDict\n",
    "        fullUserDict['address'] = addressDict\n",
    "        \n",
    "        \n",
    "        # display the PostgreSQL database server version\n",
    "        #db_version = cur.fetchone()\n",
    "        #print(db_version)\n",
    "       \n",
    "\t# close the communication with the PostgreSQL\n",
    "        cur.close()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()\n",
    "            print('Database connection closed.')\n",
    "            #print(fullUserDict)\n",
    "            return fullUserDict\n",
    "            \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    connect()\n",
    "    \n",
    "fullUserDict = connect()\n",
    "print(fullUserDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d8197a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72250a70",
   "metadata": {},
   "source": [
    "#### MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204c4d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "08ed88bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import bson\n",
    "import pickle\n",
    "import base64\n",
    "\n",
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "\n",
    "#use database named \"organisation\"\n",
    "mydb = myclient[\"ExamProject\"]\n",
    "\n",
    "#use collection named \"developers\"\n",
    "mycol = mydb[\"Temporary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0aa4135f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Year': 2017,\n",
       " 'Mileage': 15630,\n",
       " 'City': 'Katy',\n",
       " 'State': ' TX',\n",
       " 'Vin': '1FMJU1JT4HEA55066',\n",
       " 'Make': 'Ford',\n",
       " 'Model': 'ExpeditionXLT'}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getData(n1, n2):\n",
    "    dataList = []\n",
    "    tic = time.perf_counter()\n",
    "    for n in range(int(n1), int(n2)+1):\n",
    "        #print(n)\n",
    "        #print(r.hgetall(str(n)))\n",
    "        d = r.get(n)\n",
    "        yourdict = pickle.loads(d)\n",
    "        dataList.append(yourdict)\n",
    "    toc = time.perf_counter()\n",
    "    dataList.append(toc - tic)\n",
    "    return dataList\n",
    "\n",
    "car = getData(2,2)\n",
    "car[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "de010e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user': {'user_id': 405, 'firstName': 'Belinda', 'lastName': 'Foster', 'age': 44, 'email': 'b.foster@randatmail.com', 'role': 'user', 'address': {'address_id': 9, 'address': 'Kongshøj Allé 65', 'zipcode': 4220, 'city': 'Korsør'}}, 'car': {'Year': 2017, 'Mileage': 15630, 'City': 'Katy', 'State': ' TX', 'Vin': '1FMJU1JT4HEA55066', 'Make': 'Ford', 'Model': 'ExpeditionXLT'}}\n"
     ]
    }
   ],
   "source": [
    "booking = {}\n",
    "booking['user'] = fullUserDict\n",
    "booking['car'] = car[0]\n",
    "\n",
    "print(booking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "93cb62a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mycol.insert_one(booking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "0e1c2638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('628d2b1beedb38463899a41e'), 'Year': 2016, 'Mileage': 24925, 'City': 'Tucson', 'State': ' AZ', 'Vin': '1HGCR2F82GA002625', 'Make': 'Honda', 'Model': 'Accord'}\n",
      "{'_id': ObjectId('628d2b6ceedb38463899a41f'), 'Year': 2017, 'Mileage': 15630, 'City': 'Katy', 'State': ' TX', 'Vin': '1FMJU1JT4HEA55066', 'Make': 'Ford', 'Model': 'ExpeditionXLT'}\n",
      "{'_id': ObjectId('628dbb5deedb38463899a421'), 'user': {'user_id': 405, 'firstName': 'Belinda', 'lastName': 'Foster', 'age': 44, 'email': 'b.foster@randatmail.com', 'role': 'user', 'address': {'address_id': 9, 'address': 'Kongshøj Allé 65', 'zipcode': 4220, 'city': 'Korsør'}}, 'car': {'Year': 2017, 'Mileage': 15630, 'City': 'Katy', 'State': ' TX', 'Vin': '1FMJU1JT4HEA55066', 'Make': 'Ford', 'Model': 'ExpeditionXLT'}}\n"
     ]
    }
   ],
   "source": [
    "for x in mycol.find():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b248f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba0ed6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%writefile application.py\n",
    "\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "import redis\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "app = Flask(__name__, template_folder='hmtl_documents')\n",
    "\n",
    "# ---------------- THE CODE -------------------------\n",
    "df_carList = pd.read_csv(\"./datasets/Car_listings.csv\", delimiter=\",\")\n",
    "df_carList = df_carList.drop(['Price'], axis = 1)\n",
    "\n",
    "df_carList.to_json('./datasets/cars.json', orient='split', compression='infer', index='true')\n",
    "df = pd.read_json('./datasets/cars.json', orient ='split', compression = 'infer')\n",
    "\n",
    "r = redis.Redis(db=2)\n",
    "\n",
    "with open('./datasets/cars.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "# Loop og give hver værdi en key som er deres kolonne navn\n",
    "columns = list(df)\n",
    "listOfDict = []\n",
    "\n",
    "def smallDictFunction(co: [], di: {}) -> {}:\n",
    "    smallDicts = {}\n",
    "    for c in co:\n",
    "        for d in di:\n",
    "            if (columns.index(c) == dic.index(d)):\n",
    "                smallDicts[c] = d\n",
    "    return smallDicts\n",
    "   \n",
    "for dic in data['data']:\n",
    "    listOfDict.append(smallDictFunction(columns, dic))\n",
    "    if (data['data'].index(dic)+1 == 5):\n",
    "        break    # break here\n",
    "\n",
    "index_list = [*range(1, (len(listOfDict)+1), 1)]\n",
    "fullDict = dict(zip(index_list, listOfDict))\n",
    "\n",
    "with open(\"./datasets/carsDict.json\", \"w\") as write_file:\n",
    "    json.dump(fullDict, write_file, indent=4)\n",
    "\n",
    "with open('./datasets/carsDict.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "with r.pipeline() as pipe:\n",
    "    for dic in data:\n",
    "        #print(dic)\n",
    "        #print(data[dic])\n",
    "        pipe.hmset(dic, data[dic])\n",
    "        pipe.execute()\n",
    "r.bgsave()\n",
    "\n",
    "def getData(n1, n2):\n",
    "    dataList = []\n",
    "    tic = time.perf_counter()\n",
    "    for n in range(int(n1), int(n2)+1):\n",
    "        #print(n)\n",
    "        #print(r.hgetall(str(n)))\n",
    "        d = r.hgetall(str(n))\n",
    "        dataList.append(d)\n",
    "    toc = time.perf_counter()\n",
    "    dataList.append(toc - tic)\n",
    "    return dataList\n",
    "\n",
    "def getAttributes():\n",
    "    tic = time.perf_counter()\n",
    "    unPrettyList = list(r.hgetall('1'))\n",
    "    toc = time.perf_counter()\n",
    "    prettyList = []\n",
    "    for s in unPrettyList:\n",
    "        txt = str(s).split(\"'\")\n",
    "        prettyList.append(txt[1])\n",
    "    time2 = toc - tic\n",
    "    prettyList.append(time2)\n",
    "    return prettyList\n",
    "\n",
    "def getBySpecificAtt(n, s):\n",
    "    tic = time.perf_counter()\n",
    "    string = r.hget(n,s)\n",
    "    toc = time.perf_counter()\n",
    "    time2 = toc - tic\n",
    "    txt = str(string).split(\"'\")\n",
    "    \n",
    "    dataList = []\n",
    "    dataList.append(txt[1])\n",
    "    dataList.append(time2)\n",
    "    return dataList\n",
    "\n",
    "\n",
    "# ---------------- THE ENDPOINTS --------------------\n",
    "@app.route('/')\n",
    "def start():\n",
    "    attributes = getAttributes()\n",
    "    \n",
    "    return render_template('start.html', attributes=attributes[1:-1], time=attributes[-1])\n",
    "\n",
    "@app.route('/data', methods=['GET', 'POST'])\n",
    "def data():\n",
    "    if request.method == 'POST':\n",
    "        n1 = request.form['n1']\n",
    "        n2 = request.form['n2']\n",
    "        data = getData(n1, n2)\n",
    "          \n",
    "        return render_template(\"data.html\", data=data[int(n1):int(n2)], time=data[-1])\n",
    "    \n",
    "@app.route('/specificData', methods=['GET', 'POST'])\n",
    "def specificData():\n",
    "    if request.method == 'POST':\n",
    "        n = request.form['n']\n",
    "        s = request.form['s']\n",
    "        data = getBySpecificAtt(n, s)\n",
    "          \n",
    "        return render_template(\"specificData.html\", data=data[0], time=data[1])\n",
    "\n",
    "@app.route('/redis', methods=['GET', 'POST'])\n",
    "def predict():\n",
    "    if request.method == 'GET':\n",
    "        data = request.data\n",
    "    return render_template('redis.html', carsDict=data)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5f914d",
   "metadata": {},
   "source": [
    "http://localhost:5000/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5a5db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python application.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
