{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a67c8291",
   "metadata": {},
   "source": [
    "# Redis\n",
    "### Store cars data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4391f29",
   "metadata": {},
   "source": [
    "#### Install needed to run Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8a03c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfb81e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install flask-bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4802709",
   "metadata": {},
   "source": [
    "#### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb5887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10dc373",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_carList = pd.read_csv(\"./datasets/Car_listings.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cd33cc",
   "metadata": {},
   "source": [
    "We can see that this dataset has a Price column, which we don't need, beacuse this is a rental company where customers doesn't buy the cars. Because of this we remove the Price column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d11bd19",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_carList = df_carList.drop(['Price'], axis = 1)\n",
    "df_carList.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f38daf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_carList = df_carList.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301f275f",
   "metadata": {},
   "source": [
    "#### We need to convert the csv file to JSON, so that we can store the data in redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ad77ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_carList.to_json('./datasets/cars.json', orient='split', compression='infer', index='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28544ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('./datasets/cars.json', orient ='split', compression = 'infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb70b4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26595bf1",
   "metadata": {},
   "source": [
    "#### Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78e1d09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21835c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = redis.Redis(db=1)\n",
    "#r.flushdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bf5019",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./datasets/cars.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    " \n",
    "    # Print the type of data variable\n",
    "    #print(\"Type:\", type(data))\n",
    "    \n",
    "    #print(\"ITEMS: \", data.items())\n",
    "      \n",
    "    # Print the data of dictionary\n",
    "    #print(\"\\nData:\", data['data'][0]['ID IPEDS Occupation Parent'])\n",
    "    print(\"\\nData:\", data['data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9747219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop og give hver værdi en key som er deres kolonne navn\n",
    "columns = list(df)\n",
    "listOfDict = []\n",
    "\n",
    "def smallDictFunction(co: [], di: {}) -> {}:\n",
    "    smallDicts = {}\n",
    "    for c in co:\n",
    "        for d in di:\n",
    "            if (columns.index(c) == dic.index(d)):\n",
    "                #print(c + ': ' + str(d))\n",
    "                #print(d)\n",
    "                smallDicts[c] = d\n",
    "        \n",
    "    return smallDicts\n",
    "   \n",
    "\n",
    "for dic in data['data']:\n",
    "    listOfDict.append(smallDictFunction(columns, dic))\n",
    "    if (data['data'].index(dic)+1 == 200000):\n",
    "        break    # break here\n",
    "\n",
    "\n",
    "#print(test())\n",
    "#print(smallDicts)\n",
    "print(listOfDict)\n",
    "#print(fullDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51eb64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = [*range(1, (len(listOfDict)+1), 1)]\n",
    "len(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b58982",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped = zip(index_list, listOfDict)\n",
    "fullDict = dict(zipped)\n",
    "print(fullDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c973a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./datasets/carsDict.json\", \"w\") as write_file:\n",
    "    json.dump(fullDict, write_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05b46cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./datasets/carsDict.json') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184422c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dic in data:\n",
    "    p_mydict = pickle.dumps(data[dic])\n",
    "    r.set(dic,p_mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902ee546",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "read_dict = r.get(200000)\n",
    "yourdict = pickle.loads(read_dict)\n",
    "yourdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63283c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile redisFile.py\n",
    "\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "import redis\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "app = Flask(__name__, template_folder='hmtl_documents')\n",
    "\n",
    "\n",
    "r = redis.Redis(db=1)\n",
    "#r.flushdb()\n",
    "\n",
    "with open('./datasets/cars.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "read_dict = r.get(200000)\n",
    "yourdict = pickle.loads(read_dict)\n",
    "print(yourdict)\n",
    "\n",
    "def getData2(n):\n",
    "    dataList = []\n",
    "    tic = time.perf_counter()\n",
    "    d = r.get(n)\n",
    "    yourdict = pickle.loads(d)\n",
    "    dataList.append(yourdict)\n",
    "    toc = time.perf_counter()\n",
    "    dataList.append(toc - tic)\n",
    "    return dataList\n",
    "\n",
    "@app.route('/')\n",
    "def start():\n",
    "    #attributes = getAttributes()\n",
    "    attributes = ['1', '2']\n",
    "    return render_template('start.html', attributes=yourdict, time=attributes[-1])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ca5221",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python redisFile.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01307727",
   "metadata": {},
   "source": [
    "#### Postgres\n",
    "Vi skal kunne søge i postgres efter en person, lave den person inclussiv addresse om til dict og smide den i mongo i samme dict som redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bea23b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f657462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c6bb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    database=\"postgres\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea36b64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def config(filename='../Postgresql/postgresDB.ini', section='postgresql'):\n",
    "    # create a parser\n",
    "    parser = ConfigParser()\n",
    "    # read config file\n",
    "    parser.read(filename)\n",
    "\n",
    "    # get section, default to postgresql\n",
    "    db = {}\n",
    "    if parser.has_section(section):\n",
    "        params = parser.items(section)\n",
    "        for param in params:\n",
    "            db[param[0]] = param[1]\n",
    "    else:\n",
    "        raise Exception('Section {0} not found in the {1} file'.format(section, filename))\n",
    "\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3296fa80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Retrieving data:\n",
      "--------------\n",
      "{'user_id': 208, 'firstName': 'Alisa', 'lastName': 'Mason', 'age': 20, 'email': 'a.mason@randatmail.com', 'role': 'user'}\n",
      "--------------\n",
      "{'address_id': 7, 'address': 'Sønderstræde 88', 'zipcode': 2450, 'city': 'København SV'}\n",
      "--------------\n",
      "Database connection closed.\n",
      "Connecting to the PostgreSQL database...\n",
      "Retrieving data:\n",
      "--------------\n",
      "{'user_id': 208, 'firstName': 'Alisa', 'lastName': 'Mason', 'age': 20, 'email': 'a.mason@randatmail.com', 'role': 'user'}\n",
      "--------------\n",
      "{'address_id': 7, 'address': 'Sønderstræde 88', 'zipcode': 2450, 'city': 'København SV'}\n",
      "--------------\n",
      "Database connection closed.\n",
      "{'user_id': 208, 'firstName': 'Alisa', 'lastName': 'Mason', 'age': 20, 'email': 'a.mason@randatmail.com', 'role': 'user', 'address': {'address_id': 7, 'address': 'Sønderstræde 88', 'zipcode': 2450, 'city': 'København SV'}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def createDict(infoTuple, columnList, index):\n",
    "    infoList = []\n",
    "    for i in infoTuple:\n",
    "        infoList.append(i)\n",
    "        if (infoTuple.index(i) == index):\n",
    "            break;\n",
    "    return(dict(zip(columnList, infoList)))\n",
    "\n",
    "fullUserDict= {}\n",
    "def connect():\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # read connection parameters\n",
    "        params = config()\n",
    "\n",
    "        # connect to the PostgreSQL server\n",
    "        print('Connecting to the PostgreSQL database...')\n",
    "        conn = psycopg2.connect(**params)\n",
    "\t\t\n",
    "        # create a cursor\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "\t# execute a statement\n",
    "        print('Retrieving data:')\n",
    "        print('--------------')\n",
    "        #Retrieving data\n",
    "        cur.execute('SELECT * from users where user_id = '+str(208))\n",
    "        user = cur.fetchone()\n",
    "        cur.execute('SELECT role from roles where role_id = '+str(user[6]))\n",
    "        role = cur.fetchone()\n",
    "        # Saving the user as a dict\n",
    "        userTableColumns = ['user_id', 'firstName', 'lastName', 'age', 'email']\n",
    "        userDict = createDict(user, userTableColumns, 4)\n",
    "        userDict[\"role\"] = role[0]\n",
    "        print(userDict)\n",
    "        print('--------------')\n",
    "        \n",
    "        cur.execute('SELECT address_id from users where user_id = '+str(208))\n",
    "        address_id = cur.fetchone()\n",
    "        cur.execute('SELECT * from address where address_id = '+str(address_id[0]))\n",
    "        address = cur.fetchone()\n",
    "        zipcode = address[2]\n",
    "        cur.execute('SELECT * from cities where zipcode = '+str(zipcode))\n",
    "        city = cur.fetchone()\n",
    "        addressList = list(address)\n",
    "        addressList.append(city[1])\n",
    "        \n",
    "        addressTableColumns = ['address_id', 'address', 'zipcode', 'city']\n",
    "        addressDict = createDict(addressList, addressTableColumns, 3)\n",
    "        print(addressDict)\n",
    "        print('--------------')\n",
    "        \n",
    "        fullUserDict = userDict\n",
    "        fullUserDict['address'] = addressDict\n",
    "        \n",
    "       \n",
    "\t# close the communication with the PostgreSQL\n",
    "        cur.close()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()\n",
    "            print('Database connection closed.')\n",
    "            #print(fullUserDict)\n",
    "            return fullUserDict\n",
    "            \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    connect()\n",
    "    \n",
    "fullUserDict = connect()\n",
    "print(fullUserDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17552029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "093f98d0",
   "metadata": {},
   "source": [
    "#### MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e034d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "880270ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import bson\n",
    "import pickle\n",
    "import base64\n",
    "\n",
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "\n",
    "#use database named \"organisation\"\n",
    "mydb = myclient[\"ExamProject\"]\n",
    "\n",
    "#use collection named \"developers\"\n",
    "mycol = mydb[\"Temporary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "45fde10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Year': 2014,\n",
       " 'Mileage': 35725,\n",
       " 'City': 'El Paso',\n",
       " 'State': ' TX',\n",
       " 'Vin': '19VDE2E53EE000083',\n",
       " 'Make': 'Acura',\n",
       " 'Model': 'ILX6-Speed'}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getData2(n1, n2):\n",
    "    dataList = []\n",
    "    tic = time.perf_counter()\n",
    "    for n in range(int(n1), int(n2)+1):\n",
    "        #print(n)\n",
    "        #print(r.hgetall(str(n)))\n",
    "        d = r.get(n)\n",
    "        yourdict = pickle.loads(d)\n",
    "        dataList.append(yourdict)\n",
    "    toc = time.perf_counter()\n",
    "    dataList.append(toc - tic)\n",
    "    return dataList\n",
    "\n",
    "def getData(n):\n",
    "    dataList = []\n",
    "    tic = time.perf_counter()\n",
    "    d = r.get(n)\n",
    "    yourdict = pickle.loads(d)\n",
    "    dataList.append(yourdict)\n",
    "    toc = time.perf_counter()\n",
    "    dataList.append(toc - tic)\n",
    "    return dataList\n",
    "\n",
    "car = getData(1)\n",
    "car[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f083868d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user': {'user_id': 208, 'firstName': 'Alisa', 'lastName': 'Mason', 'age': 20, 'email': 'a.mason@randatmail.com', 'role': 'user', 'address': {'address_id': 7, 'address': 'Sønderstræde 88', 'zipcode': 2450, 'city': 'København SV'}}, 'car': {'Year': 2014, 'Mileage': 35725, 'City': 'El Paso', 'State': ' TX', 'Vin': '19VDE2E53EE000083', 'Make': 'Acura', 'Model': 'ILX6-Speed'}}\n"
     ]
    }
   ],
   "source": [
    "booking = {}\n",
    "booking['user'] = fullUserDict\n",
    "booking['car'] = car[0]\n",
    "\n",
    "print(booking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b76936f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mycol.insert_one(booking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a2e5139f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('628dbb5deedb38463899a421'), 'user': {'user_id': 405, 'firstName': 'Belinda', 'lastName': 'Foster', 'age': 44, 'email': 'b.foster@randatmail.com', 'role': 'user', 'address': {'address_id': 9, 'address': 'Kongshøj Allé 65', 'zipcode': 4220, 'city': 'Korsør'}}, 'car': {'Year': 2017, 'Mileage': 15630, 'City': 'Katy', 'State': ' TX', 'Vin': '1FMJU1JT4HEA55066', 'Make': 'Ford', 'Model': 'ExpeditionXLT'}}\n",
      "------------------\n",
      "{'_id': ObjectId('628dd5e5ca6d87335a883c75'), 'user': {'user_id': 405, 'firstName': 'Belinda', 'lastName': 'Foster', 'age': 44, 'email': 'b.foster@randatmail.com', 'role': 'user', 'address': {'address_id': 9, 'address': 'Kongshøj Allé 65', 'zipcode': 4220, 'city': 'Korsør'}}, 'car': {'Year': 2014, 'Mileage': 35725, 'City': 'El Paso', 'State': ' TX', 'Vin': '19VDE2E53EE000083', 'Make': 'Acura', 'Model': 'ILX6-Speed'}}\n",
      "------------------\n",
      "{'_id': ObjectId('628df1b3ca6d87335a883c76'), 'user': {'user_id': 208, 'firstName': 'Alisa', 'lastName': 'Mason', 'age': 20, 'email': 'a.mason@randatmail.com', 'role': 'user', 'address': {'address_id': 7, 'address': 'Sønderstræde 88', 'zipcode': 2450, 'city': 'København SV'}}, 'car': {'Year': 2014, 'Mileage': 35725, 'City': 'El Paso', 'State': ' TX', 'Vin': '19VDE2E53EE000083', 'Make': 'Acura', 'Model': 'ILX6-Speed'}}\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "for x in mycol.find():\n",
    "    print(x)\n",
    "    print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd7175d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b916a0c8",
   "metadata": {},
   "source": [
    "#### Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a0c9fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neo4j in c:\\users\\miade\\anaconda3\\lib\\site-packages (4.4.dev0)\n",
      "Requirement already satisfied: pytz in c:\\users\\miade\\anaconda3\\lib\\site-packages (from neo4j) (2021.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3c83ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "from neo4j.exceptions import ServiceUnavailable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bc4acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805291d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eed8fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648acb74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c020983e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f1b466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d446062",
   "metadata": {},
   "source": [
    "# DENNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "140ebf8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "{'Year': 2017, 'Mileage': 15630, 'City': 'Katy', 'State': ' TX', 'Vin': '1FMJU1JT4HEA55066', 'Make': 'Ford', 'Model': 'ExpeditionXLT'}\n",
      "[405, 'Belinda', 'Foster', 44, 'b.foster@randatmail.com', 'Kongshøj Allé 65', 4220, 'Korsør', 2017, 15630, 'Katy', ' TX', '1FMJU1JT4HEA55066', 'Ford', 'ExpeditionXLT']\n",
      "Created friendship between: 405, 2017 from None\n",
      "------------------\n",
      "--------------\n",
      "{'Year': 2014, 'Mileage': 35725, 'City': 'El Paso', 'State': ' TX', 'Vin': '19VDE2E53EE000083', 'Make': 'Acura', 'Model': 'ILX6-Speed'}\n",
      "[405, 'Belinda', 'Foster', 44, 'b.foster@randatmail.com', 'Kongshøj Allé 65', 4220, 'Korsør', 2014, 35725, 'El Paso', ' TX', '19VDE2E53EE000083', 'Acura', 'ILX6-Speed']\n",
      "Created friendship between: 405, 2014 from None\n",
      "------------------\n",
      "--------------\n",
      "{'Year': 2014, 'Mileage': 35725, 'City': 'El Paso', 'State': ' TX', 'Vin': '19VDE2E53EE000083', 'Make': 'Acura', 'Model': 'ILX6-Speed'}\n",
      "[208, 'Alisa', 'Mason', 20, 'a.mason@randatmail.com', 'Sønderstræde 88', 2450, 'København SV', 2014, 35725, 'El Paso', ' TX', '19VDE2E53EE000083', 'Acura', 'ILX6-Speed']\n",
      "Created friendship between: 208, 2014 from None\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "class App:\n",
    "\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password), database='analisys')\n",
    "\n",
    "    def close(self):\n",
    "        # Don't forget to close the driver connection when you are finished with it\n",
    "        self.driver.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def enable_log(level, output_stream):\n",
    "        handler = logging.StreamHandler(output_stream)\n",
    "        handler.setLevel(level)\n",
    "        logging.getLogger(\"neo4j\").addHandler(handler)\n",
    "        logging.getLogger(\"neo4j\").setLevel(level)\n",
    "\n",
    "    def create_friendship(self, user_id, \n",
    "                      firstName, \n",
    "                      lastName,\n",
    "                      age,\n",
    "                      email,\n",
    "                      address,\n",
    "                      zipcode,\n",
    "                      city,\n",
    "                      year,\n",
    "                      mileage,\n",
    "                      cityC,\n",
    "                      state,\n",
    "                      vin,\n",
    "                      make,\n",
    "                      model, books):\n",
    "        with self.driver.session() as session:\n",
    "            # Write transactions allow the driver to handle retries and transient errors\n",
    "            result = session.write_transaction(\n",
    "                self._create_and_return_friendship, user_id, \n",
    "                      firstName, \n",
    "                      lastName,\n",
    "                      age,\n",
    "                      email,\n",
    "                      address,\n",
    "                      zipcode,\n",
    "                      city,\n",
    "                      year,\n",
    "                      mileage,\n",
    "                      cityC,\n",
    "                      state,\n",
    "                      vin,\n",
    "                      make,\n",
    "                      model, books)\n",
    "            for row in result:\n",
    "                print(\"Created friendship between: {u}, {c} from {books}\"\n",
    "                      .format(\n",
    "                          u=row['u'],\n",
    "                          c=row['c'],\n",
    "                          books=row['books']))\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_and_return_friendship(tx, user_id, \n",
    "                      firstName, \n",
    "                      lastName,\n",
    "                      age,\n",
    "                      email,\n",
    "                      address,\n",
    "                      zipcode,\n",
    "                      city,\n",
    "                      year,\n",
    "                      mileage,\n",
    "                      cityC,\n",
    "                      state,\n",
    "                      vin,\n",
    "                      make,\n",
    "                      model, books):\n",
    "        # To learn more about the Cypher syntax, see https://neo4j.com/docs/cypher-manual/current/\n",
    "        # The Reference Card is also a good resource for keywords https://neo4j.com/docs/cypher-refcard/current/\n",
    "        query = (\n",
    "            \"MERGE (u:User { user_id: $user_id, firstName: $firstName, lastName: $lastName, age: $age, email: $email, address: $address, zipcode: $zipcode, city: $city}) \"\n",
    "            \"MERGE (c:Car { year: $year, mileage: $mileage, cityC: $cityC, state: $state, vin: $vin, make: $make, model: $model }) \"\n",
    "            \"MERGE (u)-[k:BOOKS { from: $books }]->(c) \"\n",
    "            \"RETURN u, c, k\"\n",
    "        )\n",
    "        result = tx.run(query, user_id=user_id, firstName=firstName, lastName=lastName, age=age, email=email, \n",
    "                        address=address, zipcode=zipcode, city=city, year=year, mileage=mileage, cityC=cityC, state=state,\n",
    "                        vin=vin, make=make, model=model, books=books)\n",
    "        try:\n",
    "            return [{\n",
    "                        \"u\": row[\"u\"][\"user_id\"],\n",
    "                        \"c\": row[\"c\"][\"year\"],\n",
    "                        \"books\": row[\"k\"][\"books\"]\n",
    "                    }\n",
    "                    for row in result]\n",
    "        # Capture any errors along with the query and data for traceability\n",
    "        except ServiceUnavailable as exception:\n",
    "            logging.error(\"{query} raised an error: \\n {exception}\".format(\n",
    "                query=query, exception=exception))\n",
    "            raise\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    bolt_url = \"bolt://localhost:7687\"\n",
    "    user = \"neo4j\"\n",
    "    password = \"1234\"\n",
    "    App.enable_log(logging.INFO, sys.stdout)\n",
    "    app = App(bolt_url, user, password)\n",
    "    \n",
    "    infoList = []\n",
    "    for x in mycol.find():\n",
    "        #print(list(x.values())[1])\n",
    "        for key, values in x.items():\n",
    "            if (key == 'user'):\n",
    "                #x = thisdict[\"model\"]\n",
    "                listVU = list(values)\n",
    "                #print(values)\n",
    "\n",
    "                for k, v in values.items():\n",
    "                    infoList.append(v)\n",
    "                infoList.pop()\n",
    "                infoList.pop()\n",
    "                for k, v in values['address'].items():\n",
    "                    infoList.append(v)\n",
    "                del infoList[5]\n",
    "                #print(listVU)\n",
    "                print('--------------')\n",
    "            if (key == 'car'):\n",
    "                print(values)\n",
    "                for k, v in values.items():\n",
    "                    infoList.append(v)\n",
    "            #print('key: ' + key)\n",
    "            #print('values: ' + str(values))\n",
    "        print(infoList)\n",
    "        app.create_friendship(infoList[0], infoList[1], infoList[2], infoList[3], infoList[4], infoList[5], \n",
    "                              infoList[6], infoList[7], infoList[8], infoList[9], infoList[10], infoList[11], \n",
    "                              infoList[12], infoList[13], infoList[14], 'books')\n",
    "        print('------------------')\n",
    "        infoList = []\n",
    "    \n",
    "    #app.create_friendship(405, 'Belinda', 'Foster', 44, 'b.foster@randatmail.com', 'Kongshøj Allé 65', 4220, 'Korsør',\n",
    "                         #2017, 15630, 'Katy', 'TX', '1FMJU1JT4HEA55066', 'Ford', 'ExpeditionXLT', 'books')\n",
    "    #app.find_person(\"Alice\")\n",
    "    \n",
    "    app.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d41f81f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54df6fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e2c7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c6bbf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56926be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee4ed2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92de8de1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba0ed6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%writefile application2.py\n",
    "\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "import redis\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from redisFile import getData2\n",
    "#import redisFile.py as redisFile\n",
    "\n",
    "app = Flask(__name__, template_folder='hmtl_documents')\n",
    "\n",
    "# ---------------- THE CODE -------------------------\n",
    "df_carList = pd.read_csv(\"./datasets/Car_listings.csv\", delimiter=\",\")\n",
    "df_carList = df_carList.drop(['Price'], axis = 1)\n",
    "\n",
    "df_carList.to_json('./datasets/cars.json', orient='split', compression='infer', index='true')\n",
    "df = pd.read_json('./datasets/cars.json', orient ='split', compression = 'infer')\n",
    "\n",
    "r = redis.Redis(db=1)\n",
    "\n",
    "with open('./datasets/cars.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "# Loop og give hver værdi en key som er deres kolonne navn\n",
    "columns = list(df)\n",
    "listOfDict = []\n",
    "\n",
    "def smallDictFunction(co: [], di: {}) -> {}:\n",
    "    smallDicts = {}\n",
    "    for c in co:\n",
    "        for d in di:\n",
    "            if (columns.index(c) == dic.index(d)):\n",
    "                smallDicts[c] = d\n",
    "    return smallDicts\n",
    "   \n",
    "for dic in data['data']:\n",
    "    listOfDict.append(smallDictFunction(columns, dic))\n",
    "    if (data['data'].index(dic)+1 == 5):\n",
    "        break    # break here\n",
    "\n",
    "index_list = [*range(1, (len(listOfDict)+1), 1)]\n",
    "fullDict = dict(zip(index_list, listOfDict))\n",
    "\n",
    "with open(\"./datasets/carsDict.json\", \"w\") as write_file:\n",
    "    json.dump(fullDict, write_file, indent=4)\n",
    "\n",
    "with open('./datasets/carsDict.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "for dic in data:\n",
    "    p_mydict = pickle.dumps(data[dic])\n",
    "    r.set(dic,p_mydict)\n",
    "\n",
    "def getData3(n):\n",
    "    dataList = []\n",
    "    tic = time.perf_counter()\n",
    "    d = r.get(n)\n",
    "    yourdict = pickle.loads(d)\n",
    "    dataList.append(yourdict)\n",
    "    toc = time.perf_counter()\n",
    "    dataList.append(toc - tic)\n",
    "    return dataList\n",
    "\n",
    "def getAttributes():\n",
    "    tic = time.perf_counter()\n",
    "    unPrettyList = list(r.get('1'))\n",
    "    toc = time.perf_counter()\n",
    "    prettyList = []\n",
    "    for s in unPrettyList:\n",
    "        txt = str(s).split(\"'\")\n",
    "        prettyList.append(txt[1])\n",
    "    time2 = toc - tic\n",
    "    prettyList.append(time2)\n",
    "    return prettyList\n",
    "\n",
    "def getBySpecificAtt(n, s):\n",
    "    tic = time.perf_counter()\n",
    "    string = r.get(n,s)\n",
    "    toc = time.perf_counter()\n",
    "    time2 = toc - tic\n",
    "    txt = str(string).split(\"'\")\n",
    "    \n",
    "    dataList = []\n",
    "    dataList.append(txt[1])\n",
    "    dataList.append(time2)\n",
    "    return dataList\n",
    "\n",
    "\n",
    "# ---------------- THE ENDPOINTS --------------------\n",
    "@app.route('/')\n",
    "def start():\n",
    "    #attributes = getAttributes()\n",
    "    attributes = ['1', '2']\n",
    "    return render_template('start.html', attributes=attributes[1:-1], time=attributes[-1])\n",
    "\n",
    "@app.route('/data', methods=['GET', 'POST'])\n",
    "def data():\n",
    "    if request.method == 'POST':\n",
    "        n = request.form['n']\n",
    "        data = getData2(n)\n",
    "          \n",
    "        return render_template(\"data.html\", data=data[int(n)], time=data[-1])\n",
    "    \n",
    "@app.route('/specificData', methods=['GET', 'POST'])\n",
    "def specificData():\n",
    "    if request.method == 'POST':\n",
    "        n = request.form['n']\n",
    "        s = request.form['s']\n",
    "        data = getBySpecificAtt(n, s)\n",
    "          \n",
    "        return render_template(\"specificData.html\", data=data[0], time=data[1])\n",
    "\n",
    "@app.route('/redis', methods=['GET', 'POST'])\n",
    "def predict():\n",
    "    if request.method == 'GET':\n",
    "        data = request.data\n",
    "    return render_template('redis.html', carsDict=data)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "672eb2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing application3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile application3.py\n",
    "\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "\n",
    "app = Flask(__name__, template_folder='hmtl_documents')\n",
    "\n",
    "@app.route('/')\n",
    "def start():\n",
    "    return render_template('start2.html')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5f914d",
   "metadata": {},
   "source": [
    "http://localhost:5000/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc5a5db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python application3.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
